<!--
This file is generated by an automated assistant to help AI coding agents work with this repo.
Edit to add more repository-specific commands/examples.
-->
# Copilot / AI agent instructions for this repository

Purpose: give a short, practical guide so an AI coding agent can be productive quickly in this monorepo.

1) Top-level orientation

- Primary workspace roots: `apps/*` (Next.js app at `apps/web`) and `packages/*` (Prisma db and helper libs).
- Start by reading these files (in order): `README.md`, `package.json`, `pnpm-workspace.yaml`, `apps/web/package.json`, `packages/db/schema.prisma`, `.env.example`, and `.github/workflows/ci.yml`.

2) How to run / build / test

- Install: `pnpm i`
- Start DB: `docker compose up -d`
- Push schema (prototype): `pnpm db:push`
- Dev server (web): `pnpm dev` (runs Next.js in `apps/web`)
- Unit tests: `pnpm test` (runs Vitest)
- E2E tests: `pnpm test:e2e` (runs Playwright)

3) Project-specific conventions

- Server-first: `apps/web` uses the App Router and keeps server code under `app` and `app/actions`.
- Database layer: `packages/db` holds `schema.prisma` and a Prisma client in `packages/db/src/client.ts`.
- Libraries: `packages/lib` contains pure JS/TS modules (`sim`, `plan`, `tax`) that should avoid runtime side effects and be unit-testable.
- Keep UI components in `apps/web/components` and export from `components/index.ts`.

4) Integration and deploy

- Local DB is Postgres via `docker-compose.yml` (Postgres 16). Env variables live in `.env.example`.
- Cloud: `render.yaml` contains a Render blueprint (Postgres + web service). Pre-deploy runs `pnpm db:migrate`.
- Optional Vercel usage: app can be deployed to Vercel; ensure `DATABASE_URL` points to a managed DB.

5) Files to read for common tasks

- To run migrations / db work: `packages/db/schema.prisma`, `packages/db/README.md`.
- To modify the app: `apps/web/app/(marketing)/page.tsx`, `apps/web/app/api/health/route.ts`, `apps/web/lib/env.ts`.
- To add tests: `packages/lib/sim/__tests__/smoke.test.ts` and `tests/e2e/health.spec.ts` show patterns for unit and e2e tests.

6) Editing and PR guidance for the agent

- Keep changes minimal and add a small unit test when adding behaviour.
- When adding or changing env vars, update `.env.example` and `README.md`.
- If you add build/test commands, update `package.json` and CI workflow under `.github/workflows/`.

7) When info is missing

- This repo currently contains scaffolding. If you need more specifics (preferred package versions, CI secrets, or monorepo tooling choices), either ask the maintainer or add top-level manifests (`README.md`, `package.json`, etc.) and re-run discovery.

If you want a deeper, tailored agent guide including example commands and file-level contracts, add the project's real source files (or tell me which folders/files to prioritize) and I'll merge concrete examples into this file.
<!--
This file is generated by an automated assistant when no repository-level
agent guidance was found. Edit to add project-specific commands/examples.
-->
# Copilot / AI agent instructions for this repository

Purpose: give a short, practical guide so an AI coding agent can be productive quickly.

Keep this file concise (20–50 lines). Only include discoverable, actionable items.

1) Top-level repo orientation

- If present, start by reading these files (in order): `README.md`, `package.json`, `pyproject.toml`, `go.mod`, `Cargo.toml`, `Makefile`, `Dockerfile`, `.github/workflows/*.yml`.
- This repository currently has no discoverable files in the workspace root. If you (human) add them, include the primary build/test commands below so agents can run them.

2) How to run / build / test (discoverable patterns)

- If `package.json` exists, use `npm run <script>` or `yarn <script>` — common scripts: `dev`, `start`, `build`, `test`.
- If `pyproject.toml` or `requirements.txt` exists, prefer `python -m venv .venv && . .venv/bin/activate` and `pip install -r requirements.txt` or `pip install -e .` then `pytest` for tests.
- If `Makefile` exists, use `make help` to discover targets.
- If `Dockerfile` exists and there's no explicit build system, use `docker build -t repo-image .` then run containers for integration verification.

3) Repository-specific conventions and patterns (discoverable guidance)

- If a `src/` folder exists, prefer editing files there. If a `lib/` or `pkg/` folder exists, follow that layout.
- Prefix branch names for features as `feat/` and for fixes as `fix/` when creating commits (common pattern if CI expects it).
- Tests are typically kept under `tests/` or alongside modules as `module_test.*` files; run `pytest` or `npm test` as appropriate.

4) Integration points and dependencies

- Check for lockfiles (`package-lock.json`, `poetry.lock`, `Pipfile.lock`, `pnpm-lock.yaml`) to know exact dependency versions.
- Look for environment config in `.env`, `.env.example`, or `config/` directory. Do not print secrets — only read schema-like examples.

5) Editing and PR guidance for the agent

- Keep changes minimal and scoped. When adding new functionality, include one small unit test or repro case.
- If updating build/test commands, update README and add or update CI under `.github/workflows/`.

6) When you can't find necessary info

- If the repository lacks top-level manifests or a README (as here), create a short `README.md` stub describing the language/runtime and the canonical commands to build/test/run. Mark assumptions in the README.

7) Checklist for agent commits

- Files changed are limited to feature area (avoid large unrelated refactors).
- Add or update tests for new behavior when feasible.
- Update README or docs for new public commands or environment variables.

---
If you want me to customize these instructions to real files in this repo, please either (a) add the repository files (README, package.json, etc.) or (b) tell me where the source is located and I will re-run discovery and produce a merged, example-filled `.github/copilot-instructions.md`.

Please tell me any conventions you want enforced (branch naming, test runner, preferred formatting tool) and I'll merge them into this file.
